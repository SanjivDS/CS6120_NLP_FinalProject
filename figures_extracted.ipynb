{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dab784-22a9-4fd4-8227-ee380398ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extraction from /Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/pdfs\n",
      "\n",
      "Processing: 104.pdf\n",
      "Extracted 17 tables and 7 figures\n",
      "\n",
      "Processing: 105.pdf\n",
      "Extracted 10 tables and 6 figures\n",
      "\n",
      "Processing: 107.pdf\n",
      "Extracted 12 tables and 2 figures\n",
      "\n",
      "Processing: 108.pdf\n",
      "Extracted 9 tables and 0 figures\n",
      "\n",
      "Processing: 117.pdf\n",
      "Extracted 7 tables and 0 figures\n",
      "\n",
      "Processing: 12.pdf\n",
      "Extracted 10 tables and 1 figures\n",
      "\n",
      "Processing: 122.pdf\n",
      "Extracted 3 tables and 3 figures\n",
      "\n",
      "Processing: 128.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 130.pdf\n",
      "Extracted 5 tables and 25 figures\n",
      "\n",
      "Processing: 134.pdf\n",
      "Extracted 2 tables and 0 figures\n",
      "\n",
      "Processing: 145.pdf\n",
      "Extracted 0 tables and 5 figures\n",
      "\n",
      "Processing: 150.pdf\n",
      "Extracted 11 tables and 1 figures\n",
      "\n",
      "Processing: 16.pdf\n",
      "Extracted 8 tables and 3 figures\n",
      "\n",
      "Processing: 169.pdf\n",
      "Extracted 13 tables and 0 figures\n",
      "\n",
      "Processing: 178.pdf\n",
      "Extracted 14 tables and 3 figures\n",
      "\n",
      "Processing: 18.pdf\n",
      "Extracted 5 tables and 0 figures\n",
      "\n",
      "Processing: 180.pdf\n",
      "Extracted 8 tables and 0 figures\n",
      "\n",
      "Processing: 182.pdf\n",
      "Extracted 10 tables and 29 figures\n",
      "\n",
      "Processing: 19.pdf\n",
      "Extracted 2 tables and 0 figures\n",
      "\n",
      "Processing: 193.pdf\n",
      "Extracted 6 tables and 0 figures\n",
      "\n",
      "Processing: 201.pdf\n",
      "Extracted 47 tables and 0 figures\n",
      "\n",
      "Processing: 21.pdf\n",
      "Extracted 10 tables and 8 figures\n",
      "\n",
      "Processing: 214.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 216.pdf\n",
      "Extracted 12 tables and 0 figures\n",
      "\n",
      "Processing: 220.pdf\n",
      "Extracted 0 tables and 5 figures\n",
      "\n",
      "Processing: 222.pdf\n",
      "Extracted 4 tables and 11 figures\n",
      "\n",
      "Processing: 226.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 237.pdf\n",
      "Extracted 2 tables and 2 figures\n",
      "\n",
      "Processing: 239.pdf\n",
      "Extracted 0 tables and 4 figures\n",
      "\n",
      "Processing: 251.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 256.pdf\n",
      "Extracted 8 tables and 7 figures\n",
      "\n",
      "Processing: 26.pdf\n",
      "Extracted 0 tables and 6 figures\n",
      "\n",
      "Processing: 266.pdf\n",
      "Extracted 6 tables and 3 figures\n",
      "\n",
      "Processing: 270.pdf\n",
      "Extracted 6 tables and 8 figures\n",
      "\n",
      "Processing: 276.pdf\n",
      "Extracted 0 tables and 3 figures\n",
      "\n",
      "Processing: 288.pdf\n",
      "Extracted 12 tables and 0 figures\n",
      "\n",
      "Processing: 31.pdf\n",
      "Extracted 15 tables and 0 figures\n",
      "\n",
      "Processing: 318.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 326.pdf\n",
      "Extracted 12 tables and 0 figures\n",
      "\n",
      "Processing: 33.pdf\n",
      "Extracted 8 tables and 2 figures\n",
      "\n",
      "Processing: 331.pdf\n",
      "Extracted 1 tables and 0 figures\n",
      "\n",
      "Processing: 333.pdf\n",
      "Extracted 2 tables and 3 figures\n",
      "\n",
      "Processing: 335.pdf\n",
      "Extracted 4 tables and 5 figures\n",
      "\n",
      "Processing: 338.pdf\n",
      "Extracted 8 tables and 40 figures\n",
      "\n",
      "Processing: 343.pdf\n",
      "Extracted 8 tables and 0 figures\n",
      "\n",
      "Processing: 350.pdf\n",
      "Extracted 10 tables and 79 figures\n",
      "\n",
      "Processing: 365.pdf\n",
      "Extracted 8 tables and 6 figures\n",
      "\n",
      "Processing: 367.pdf\n",
      "Extracted 18 tables and 3 figures\n",
      "\n",
      "Processing: 369.pdf\n",
      "Extracted 7 tables and 3 figures\n",
      "\n",
      "Processing: 375.pdf\n",
      "Extracted 2 tables and 4 figures\n",
      "\n",
      "Processing: 376.pdf\n",
      "Extracted 10 tables and 2 figures\n",
      "\n",
      "Processing: 382.pdf\n",
      "Extracted 0 tables and 1 figures\n",
      "\n",
      "Processing: 384.pdf\n",
      "Extracted 13 tables and 0 figures\n",
      "\n",
      "Processing: 387.pdf\n",
      "Extracted 14 tables and 23 figures\n",
      "\n",
      "Processing: 388.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 395.pdf\n",
      "Extracted 7 tables and 3 figures\n",
      "\n",
      "Processing: 419.pdf\n",
      "Extracted 5 tables and 4 figures\n",
      "\n",
      "Processing: 433.pdf\n",
      "Extracted 9 tables and 4 figures\n",
      "\n",
      "Processing: 440.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 444.pdf\n",
      "Extracted 5 tables and 3 figures\n",
      "\n",
      "Processing: 447.pdf\n",
      "Extracted 2 tables and 0 figures\n",
      "\n",
      "Processing: 462.pdf\n",
      "Extracted 9 tables and 53 figures\n",
      "\n",
      "Processing: 467.pdf\n",
      "Extracted 3 tables and 1 figures\n",
      "\n",
      "Processing: 477.pdf\n",
      "Extracted 10 tables and 0 figures\n",
      "\n",
      "Processing: 481.pdf\n",
      "Extracted 11 tables and 2 figures\n",
      "\n",
      "Processing: 483.pdf\n",
      "Extracted 12 tables and 16 figures\n",
      "\n",
      "Processing: 484.pdf\n",
      "Extracted 8 tables and 117 figures\n",
      "\n",
      "Processing: 494.pdf\n",
      "Extracted 5 tables and 0 figures\n",
      "\n",
      "Processing: 501.pdf\n",
      "Extracted 5 tables and 3 figures\n",
      "\n",
      "Processing: 503.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 516.pdf\n",
      "Extracted 0 tables and 1 figures\n",
      "\n",
      "Processing: 520.pdf\n",
      "Extracted 19 tables and 12 figures\n",
      "\n",
      "Processing: 524.pdf\n",
      "Extracted 4 tables and 0 figures\n",
      "\n",
      "Processing: 543.pdf\n",
      "Extracted 9 tables and 45 figures\n",
      "\n",
      "Processing: 553.pdf\n",
      "Extracted 7 tables and 0 figures\n",
      "\n",
      "Processing: 554.pdf\n",
      "Extracted 7 tables and 33 figures\n",
      "\n",
      "Processing: 557.pdf\n",
      "Extracted 10 tables and 0 figures\n",
      "\n",
      "Processing: 56.pdf\n",
      "Extracted 8 tables and 4 figures\n",
      "\n",
      "Processing: 561.pdf\n",
      "Extracted 10 tables and 0 figures\n",
      "\n",
      "Processing: 562.pdf\n",
      "Extracted 10 tables and 1 figures\n",
      "\n",
      "Processing: 563.pdf\n",
      "Extracted 0 tables and 1 figures\n",
      "\n",
      "Processing: 564.pdf\n",
      "Extracted 5 tables and 3 figures\n",
      "\n",
      "Processing: 578.pdf\n",
      "Extracted 8 tables and 1 figures\n",
      "\n",
      "Processing: 579.pdf\n",
      "Extracted 0 tables and 1 figures\n",
      "\n",
      "Processing: 588.pdf\n",
      "Extracted 0 tables and 1 figures\n",
      "\n",
      "Processing: 606.pdf\n",
      "Extracted 13 tables and 0 figures\n",
      "\n",
      "Processing: 614.pdf\n",
      "Extracted 4 tables and 0 figures\n",
      "\n",
      "Processing: 619.pdf\n",
      "Extracted 8 tables and 2 figures\n",
      "\n",
      "Processing: 627.pdf\n",
      "Extracted 3 tables and 6 figures\n",
      "\n",
      "Processing: 636.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 649.pdf\n",
      "Extracted 7 tables and 5 figures\n",
      "\n",
      "Processing: 654.pdf\n",
      "Extracted 6 tables and 15 figures\n",
      "\n",
      "Processing: 657.pdf\n",
      "Extracted 1 tables and 6 figures\n",
      "\n",
      "Processing: 66.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 67.pdf\n",
      "Extracted 8 tables and 8 figures\n",
      "\n",
      "Processing: 676.pdf\n",
      "Extracted 8 tables and 0 figures\n",
      "\n",
      "Processing: 68.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 684.pdf\n",
      "Extracted 28 tables and 10 figures\n",
      "\n",
      "Processing: 691.pdf\n",
      "Extracted 6 tables and 5 figures\n",
      "\n",
      "Processing: 699.pdf\n",
      "Extracted 6 tables and 1 figures\n",
      "\n",
      "Processing: 706.pdf\n",
      "Extracted 10 tables and 4 figures\n",
      "\n",
      "Processing: 71.pdf\n",
      "Extracted 1 tables and 2 figures\n",
      "\n",
      "Processing: 715.pdf\n",
      "Extracted 6 tables and 4 figures\n",
      "\n",
      "Processing: 723.pdf\n",
      "Extracted 8 tables and 3 figures\n",
      "\n",
      "Processing: 726.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 727.pdf\n",
      "Extracted 6 tables and 8 figures\n",
      "\n",
      "Processing: 729.pdf\n",
      "Extracted 10 tables and 7 figures\n",
      "\n",
      "Processing: 741.pdf\n",
      "Extracted 6 tables and 2 figures\n",
      "\n",
      "Processing: 752.pdf\n",
      "Extracted 7 tables and 0 figures\n",
      "\n",
      "Processing: 759.pdf\n",
      "Extracted 16 tables and 6 figures\n",
      "\n",
      "Processing: 760.pdf\n",
      "Extracted 9 tables and 0 figures\n",
      "\n",
      "Processing: 769.pdf\n",
      "Extracted 2 tables and 0 figures\n",
      "\n",
      "Processing: 775.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 777.pdf\n",
      "Extracted 15 tables and 1 figures\n",
      "\n",
      "Processing: 779.pdf\n",
      "Extracted 14 tables and 0 figures\n",
      "\n",
      "Processing: 79.pdf\n",
      "Extracted 7 tables and 2 figures\n",
      "\n",
      "Processing: 792.pdf\n",
      "Extracted 0 tables and 4 figures\n",
      "\n",
      "Processing: 805.pdf\n",
      "Extracted 14 tables and 5 figures\n",
      "\n",
      "Processing: 818.pdf\n",
      "Extracted 9 tables and 7 figures\n",
      "\n",
      "Processing: 86.pdf\n",
      "Extracted 3 tables and 0 figures\n",
      "\n",
      "Processing: 87.pdf\n",
      "Extracted 7 tables and 12 figures\n",
      "\n",
      "Processing: 96.pdf\n",
      "Extracted 8 tables and 0 figures\n",
      "\n",
      "Processing: 97.pdf\n",
      "Extracted 3 tables and 1 figures\n",
      "\n",
      "Extraction complete! Processed 123/123 PDFs successfully\n",
      "Results saved to: /Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/output/extraction_20250403_164455\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path, pdfinfo_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from datetime import datetime\n",
    "\n",
    "def is_valid_pdf(pdf_path):\n",
    "    \"\"\"Check if PDF is valid and can be opened\"\"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            if len(doc) > 0:  # Check if we can get page count\n",
    "                return True\n",
    "        return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def extract_tables_and_figures(pdf_path, output_folder, dpi=300):\n",
    "    \"\"\"Robust extraction of tables and figures with error handling\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    results = {\n",
    "        'tables': [],\n",
    "        'figures': [],\n",
    "        'errors': []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # First try with PyMuPDF for metadata and embedded figures\n",
    "        try:\n",
    "            with fitz.open(pdf_path) as doc:\n",
    "                # Extract embedded figures\n",
    "                for page_num in range(len(doc)):\n",
    "                    page = doc.load_page(page_num)\n",
    "                    images = page.get_images(full=True)\n",
    "                    \n",
    "                    for img_index, img in enumerate(images):\n",
    "                        try:\n",
    "                            xref = img[0]\n",
    "                            base_image = doc.extract_image(xref)\n",
    "                            img_path = os.path.join(\n",
    "                                output_folder,\n",
    "                                f\"page_{page_num+1}_fig_{img_index+1}.{base_image['ext']}\"\n",
    "                            )\n",
    "                            with open(img_path, \"wb\") as f:\n",
    "                                f.write(base_image[\"image\"])\n",
    "                            results['figures'].append({\n",
    "                                'page': page_num + 1,\n",
    "                                'path': img_path,\n",
    "                                'type': 'embedded_figure'\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            results['errors'].append(f\"Page {page_num+1} figure error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            results['errors'].append(f\"PyMuPDF error: {str(e)}\")\n",
    "\n",
    "        # Then try with pdf2image for table extraction\n",
    "        try:\n",
    "            # Check if we can get page count first\n",
    "            info = pdfinfo_from_path(pdf_path)\n",
    "            pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "            \n",
    "            for page_num, page in enumerate(pages):\n",
    "                try:\n",
    "                    temp_path = os.path.join(output_folder, f\"temp_page_{page_num}.png\")\n",
    "                    page.save(temp_path, \"PNG\")\n",
    "                    img = cv2.imread(temp_path)\n",
    "                    \n",
    "                    if img is not None:\n",
    "                        # Table detection\n",
    "                        tables = detect_tables(img)\n",
    "                        for i, table in enumerate(tables):\n",
    "                            table_path = os.path.join(\n",
    "                                output_folder,\n",
    "                                f\"page_{page_num+1}_table_{i+1}.png\"\n",
    "                            )\n",
    "                            cv2.imwrite(table_path, table['image'])\n",
    "                            results['tables'].append({\n",
    "                                'page': page_num + 1,\n",
    "                                'path': table_path,\n",
    "                                'bbox': table['bbox'],\n",
    "                                'type': 'table'\n",
    "                            })\n",
    "                    \n",
    "                    os.remove(temp_path)\n",
    "                except Exception as e:\n",
    "                    results['errors'].append(f\"Page {page_num+1} processing error: {str(e)}\")\n",
    "                    if os.path.exists(temp_path):\n",
    "                        os.remove(temp_path)\n",
    "        except Exception as e:\n",
    "            results['errors'].append(f\"PDF2Image error: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        results['errors'].append(f\"General processing error: {str(e)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def detect_tables(img):\n",
    "    \"\"\"Improved table detection with multiple methods\"\"\"\n",
    "    tables = []\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Method 1: Line detection for bordered tables\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Detect lines\n",
    "    horz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "    vert_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
    "    horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horz_kernel, iterations=2)\n",
    "    vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vert_kernel, iterations=2)\n",
    "    table_mask = cv2.add(horizontal, vertical)\n",
    "    \n",
    "    # Find table contours\n",
    "    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 200 and h > 100:  # Minimum table size\n",
    "            table_img = img[y:y+h, x:x+w]\n",
    "            tables.append({\n",
    "                'image': table_img,\n",
    "                'bbox': [x, y, w, h]\n",
    "            })\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def process_pdf_folder(input_folder, output_base):\n",
    "    \"\"\"Process all PDFs in a folder with robust error handling\"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    all_results = []\n",
    "    \n",
    "    for pdf_file in sorted(f for f in os.listdir(input_folder) if f.lower().endswith('.pdf')):\n",
    "        pdf_path = os.path.join(input_folder, pdf_file)\n",
    "        paper_id = os.path.splitext(pdf_file)[0]\n",
    "        output_folder = os.path.join(output_base, paper_id)\n",
    "        \n",
    "        print(f\"\\nProcessing: {pdf_file}\")\n",
    "        \n",
    "        if not is_valid_pdf(pdf_path):\n",
    "            print(f\"Skipping invalid/corrupted PDF: {pdf_file}\")\n",
    "            all_results.append({\n",
    "                'paper': pdf_file,\n",
    "                'status': 'failed',\n",
    "                'error': 'Invalid/corrupted PDF'\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            results = extract_tables_and_figures(pdf_path, output_folder)\n",
    "            \n",
    "            # Save metadata\n",
    "            metadata = {\n",
    "                'paper': pdf_file,\n",
    "                'tables_extracted': len(results['tables']),\n",
    "                'figures_extracted': len(results['figures']),\n",
    "                'errors': results['errors'],\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(os.path.join(output_folder, 'metadata.json'), 'w') as f:\n",
    "                import json\n",
    "                json.dump(metadata, f, indent=2)\n",
    "            \n",
    "            all_results.append(metadata)\n",
    "            print(f\"Extracted {len(results['tables'])} tables and {len(results['figures'])} figures\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fatal error processing {pdf_file}: {str(e)}\")\n",
    "            all_results.append({\n",
    "                'paper': pdf_file,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_FOLDER = \"/Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/pdfs\"\n",
    "    OUTPUT_FOLDER = \"/Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/output\"\n",
    "    \n",
    "    # Create timestamped output\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_output = os.path.join(OUTPUT_FOLDER, f\"extraction_{timestamp}\")\n",
    "    \n",
    "    # Process all PDFs\n",
    "    print(f\"Starting extraction from {INPUT_FOLDER}\")\n",
    "    results = process_pdf_folder(INPUT_FOLDER, final_output)\n",
    "    \n",
    "    # Print summary\n",
    "    success = sum(1 for r in results if r.get('status') != 'failed')\n",
    "    print(f\"\\nExtraction complete! Processed {success}/{len(results)} PDFs successfully\")\n",
    "    print(f\"Results saved to: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfe9ac2-3c44-456c-8ea5-60205b314c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extraction from /Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/pdfs-1\n",
      "\n",
      "Processing: 1607.01400v1.pdf\n",
      "Extracted 10 tables and 0 figures\n",
      "\n",
      "Processing: 1612.04858v1.pdf\n",
      "Extracted 27 tables and 11 figures\n",
      "\n",
      "Processing: 1811.04422v1.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 1906.06821v2.pdf\n",
      "Extracted 0 tables and 0 figures\n",
      "\n",
      "Processing: 1907.08908v1.pdf\n",
      "Extracted 3 tables and 5 figures\n",
      "\n",
      "Processing: 1909.03550v1.pdf\n",
      "Extracted 9 tables and 6 figures\n",
      "\n",
      "Processing: 2007.01503v1.pdf\n",
      "Extracted 5 tables and 5 figures\n",
      "\n",
      "Processing: 2007.14206v1.pdf\n",
      "Extracted 15 tables and 6 figures\n",
      "\n",
      "Processing: 2104.10201v2.pdf\n",
      "Extracted 5 tables and 0 figures\n",
      "\n",
      "Processing: 2206.13446v1.pdf\n",
      "Extracted 24 tables and 1 figures\n",
      "\n",
      "Processing: 2401.04155v2.pdf\n",
      "Extracted 60 tables and 9 figures\n",
      "\n",
      "Processing: 2402.06196v3.pdf\n",
      "Extracted 48 tables and 50 figures\n",
      "\n",
      "Processing: 2405.15251v1.pdf\n",
      "Extracted 8 tables and 3 figures\n",
      "\n",
      "Extraction complete! Processed 13/13 PDFs successfully\n",
      "Results saved to: /Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/output/extraction_20250412_201018\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import fitz  # PyMuPDF\n",
    "from pdf2image import convert_from_path, pdfinfo_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from datetime import datetime\n",
    "\n",
    "def is_valid_pdf(pdf_path):\n",
    "    \"\"\"Check if PDF is valid and can be opened\"\"\"\n",
    "    try:\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            if len(doc) > 0:  # Check if we can get page count\n",
    "                return True\n",
    "        return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def extract_tables_and_figures(pdf_path, output_folder, dpi=300):\n",
    "    \"\"\"Robust extraction of tables and figures with error handling\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    results = {\n",
    "        'tables': [],\n",
    "        'figures': [],\n",
    "        'errors': []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # First try with PyMuPDF for metadata and embedded figures\n",
    "        try:\n",
    "            with fitz.open(pdf_path) as doc:\n",
    "                # Extract embedded figures\n",
    "                for page_num in range(len(doc)):\n",
    "                    page = doc.load_page(page_num)\n",
    "                    images = page.get_images(full=True)\n",
    "                    \n",
    "                    for img_index, img in enumerate(images):\n",
    "                        try:\n",
    "                            xref = img[0]\n",
    "                            base_image = doc.extract_image(xref)\n",
    "                            img_path = os.path.join(\n",
    "                                output_folder,\n",
    "                                f\"page_{page_num+1}_fig_{img_index+1}.{base_image['ext']}\"\n",
    "                            )\n",
    "                            with open(img_path, \"wb\") as f:\n",
    "                                f.write(base_image[\"image\"])\n",
    "                            results['figures'].append({\n",
    "                                'page': page_num + 1,\n",
    "                                'path': img_path,\n",
    "                                'type': 'embedded_figure'\n",
    "                            })\n",
    "                        except Exception as e:\n",
    "                            results['errors'].append(f\"Page {page_num+1} figure error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            results['errors'].append(f\"PyMuPDF error: {str(e)}\")\n",
    "\n",
    "        # Then try with pdf2image for table extraction\n",
    "        try:\n",
    "            # Check if we can get page count first\n",
    "            info = pdfinfo_from_path(pdf_path)\n",
    "            pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "            \n",
    "            for page_num, page in enumerate(pages):\n",
    "                try:\n",
    "                    temp_path = os.path.join(output_folder, f\"temp_page_{page_num}.png\")\n",
    "                    page.save(temp_path, \"PNG\")\n",
    "                    img = cv2.imread(temp_path)\n",
    "                    \n",
    "                    if img is not None:\n",
    "                        # Table detection\n",
    "                        tables = detect_tables(img)\n",
    "                        for i, table in enumerate(tables):\n",
    "                            table_path = os.path.join(\n",
    "                                output_folder,\n",
    "                                f\"page_{page_num+1}_table_{i+1}.png\"\n",
    "                            )\n",
    "                            cv2.imwrite(table_path, table['image'])\n",
    "                            results['tables'].append({\n",
    "                                'page': page_num + 1,\n",
    "                                'path': table_path,\n",
    "                                'bbox': table['bbox'],\n",
    "                                'type': 'table'\n",
    "                            })\n",
    "                    \n",
    "                    os.remove(temp_path)\n",
    "                except Exception as e:\n",
    "                    results['errors'].append(f\"Page {page_num+1} processing error: {str(e)}\")\n",
    "                    if os.path.exists(temp_path):\n",
    "                        os.remove(temp_path)\n",
    "        except Exception as e:\n",
    "            results['errors'].append(f\"PDF2Image error: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        results['errors'].append(f\"General processing error: {str(e)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def detect_tables(img):\n",
    "    \"\"\"Improved table detection with multiple methods\"\"\"\n",
    "    tables = []\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Method 1: Line detection for bordered tables\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    # Detect lines\n",
    "    horz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "    vert_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
    "    horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horz_kernel, iterations=2)\n",
    "    vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vert_kernel, iterations=2)\n",
    "    table_mask = cv2.add(horizontal, vertical)\n",
    "    \n",
    "    # Find table contours\n",
    "    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 200 and h > 100:  # Minimum table size\n",
    "            table_img = img[y:y+h, x:x+w]\n",
    "            tables.append({\n",
    "                'image': table_img,\n",
    "                'bbox': [x, y, w, h]\n",
    "            })\n",
    "    \n",
    "    return tables\n",
    "\n",
    "def process_pdf_folder(input_folder, output_base):\n",
    "    \"\"\"Process all PDFs in a folder with robust error handling\"\"\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    all_results = []\n",
    "    \n",
    "    for pdf_file in sorted(f for f in os.listdir(input_folder) if f.lower().endswith('.pdf')):\n",
    "        pdf_path = os.path.join(input_folder, pdf_file)\n",
    "        paper_id = os.path.splitext(pdf_file)[0]\n",
    "        output_folder = os.path.join(output_base, paper_id)\n",
    "        \n",
    "        print(f\"\\nProcessing: {pdf_file}\")\n",
    "        \n",
    "        if not is_valid_pdf(pdf_path):\n",
    "            print(f\"Skipping invalid/corrupted PDF: {pdf_file}\")\n",
    "            all_results.append({\n",
    "                'paper': pdf_file,\n",
    "                'status': 'failed',\n",
    "                'error': 'Invalid/corrupted PDF'\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            results = extract_tables_and_figures(pdf_path, output_folder)\n",
    "            \n",
    "            # Save metadata\n",
    "            metadata = {\n",
    "                'paper': pdf_file,\n",
    "                'tables_extracted': len(results['tables']),\n",
    "                'figures_extracted': len(results['figures']),\n",
    "                'errors': results['errors'],\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(os.path.join(output_folder, 'metadata.json'), 'w') as f:\n",
    "                import json\n",
    "                json.dump(metadata, f, indent=2)\n",
    "            \n",
    "            all_results.append(metadata)\n",
    "            print(f\"Extracted {len(results['tables'])} tables and {len(results['figures'])} figures\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fatal error processing {pdf_file}: {str(e)}\")\n",
    "            all_results.append({\n",
    "                'paper': pdf_file,\n",
    "                'status': 'failed',\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    INPUT_FOLDER = \"/Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/pdfs-1\"\n",
    "    OUTPUT_FOLDER = \"/Users/Snigdha/Desktop/NEU/NLP/Project/PeerRead-master/data/acl_2017/train/output\"\n",
    "    \n",
    "    # Create timestamped output\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_output = os.path.join(OUTPUT_FOLDER, f\"extraction_{timestamp}\")\n",
    "    \n",
    "    # Process all PDFs\n",
    "    print(f\"Starting extraction from {INPUT_FOLDER}\")\n",
    "    results = process_pdf_folder(INPUT_FOLDER, final_output)\n",
    "    \n",
    "    # Print summary\n",
    "    success = sum(1 for r in results if r.get('status') != 'failed')\n",
    "    print(f\"\\nExtraction complete! Processed {success}/{len(results)} PDFs successfully\")\n",
    "    print(f\"Results saved to: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fc04b-dfe2-4fb5-b7dc-183eb4348e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
